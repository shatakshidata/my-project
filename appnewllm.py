# -*- coding: utf-8 -*-
"""appnewllm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s1vntJ4KY5EuFcrWDbzg8OjnxdiIiwWQ
"""

from flask import Flask, request, jsonify
import google.generativeai as genai
from flask_cors import CORS

appnewllm = Flask(__name__)
CORS(appnewllm)

# Configure the Gemini API
genai.configure(api_key="AIzaSyCUYFRycP9sSMwuqDg3_P_RI_yKaWWfXtg")  # Replace with your API key

@appnewllm.route("/api/llm", methods=["POST"])
def run_llm():
    try:
        data = request.json
        task_type = data.get("taskType")
        user_input = data.get("userInput")

        if not user_input:
            return jsonify({"error": "No input provided."}), 400

        # Select the appropriate prompt based on the task type
        if task_type == "completion":
            prompt = user_input
        elif task_type == "summarization":
            prompt = f"Summarize this: {user_input}"
        elif task_type == "qa":
            prompt = f"Answer this question: {user_input}"
        else:
            return jsonify({"error": "Invalid task type."}), 400

        # Get the Gemini model
        model = genai.GenerativeModel("gemini-pro")
        response = model.generate_content(prompt)

        return jsonify({"text": response.text})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    appnewllm.run(debug=True)

